{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def parse(filename):\n",
    "  '''\n",
    "  takes a filename and returns attribute information and all the data in array of dictionaries\n",
    "  '''\n",
    "  # initialize variables\n",
    "\n",
    "  out = []  \n",
    "  csvfile = open(filename,'rb')\n",
    "  fileToRead = csv.reader(csvfile)\n",
    "\n",
    "  headers = fileToRead.next()\n",
    "\n",
    "  # iterate through rows of actual data\n",
    "  for row in fileToRead:\n",
    "    out.append(dict(zip(headers, row)))\n",
    "  return out\n",
    "\n",
    "data = parse(\"house_votes_84.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the data \n",
    "print \"Number of Observations:\" , len(data)\n",
    "data[1:3]\n",
    "attributes = data[1].keys()\n",
    "print \"Number of Attributes:\" ,len(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node import Node "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Auto Grader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3 test 1 succeeded.\n",
      "ID3 test 2 succeeded.\n",
      "ID3 test 3-1 succeeded.\n",
      "ID3 test 3-2 succeeded.\n",
      "ID3 test 4-1 succeeded.\n",
      "ID3 test 4-2 succeeded.\n"
     ]
    }
   ],
   "source": [
    "import ID3, parse, random\n",
    "\n",
    "def mini_grader():\n",
    "\n",
    "  data = [dict(a=1, b=0, Class=1), dict(a=1, b=1, Class=1)]\n",
    "\n",
    "  try:\n",
    "    tree = ID3.ID3(data, 0)\n",
    "    if tree != None:\n",
    "      ans = ID3.evaluate(tree, dict(a=1, b=0))\n",
    "      if ans != 1:\n",
    "        print \"ID3 test 1 failed.\"\n",
    "      else:\n",
    "        print \"ID3 test 1 succeeded.\"\n",
    "    else:\n",
    "      print \"ID3 test 1 failed -- no tree returned\"\n",
    "  except Exception:\n",
    "    print 'ID3 test 1 failed runtime error'\n",
    "\n",
    "  data = [dict(a=1, b=0, Class=0), dict(a=1, b=1, Class=1)]\n",
    "\n",
    "  try:\n",
    "    tree = ID3.ID3(data, 0)\n",
    "    if tree != None:\n",
    "      ans = ID3.evaluate(tree, dict(a=1, b=0))\n",
    "      if ans != 0:\n",
    "        print \"ID3 test 2 failed.\"\n",
    "      else:\n",
    "        print \"ID3 test 2 succeeded.\"\n",
    "    else:\n",
    "      print \"ID3 test 2 failed -- no tree returned\"\n",
    "  except Exception:\n",
    "    print 'ID3 test 2 failed runtime error'\n",
    "\n",
    "\n",
    "  data = [dict(a=1, b=0, Class=2), dict(a=1, b=1, Class=1),\n",
    "          dict(a=2, b=0, Class=2), dict(a=2, b=1, Class=3),\n",
    "          dict(a=3, b=0, Class=1), dict(a=3, b=1, Class=3)]\n",
    "\n",
    "  try:\n",
    "    tree = ID3.ID3(data, 0)\n",
    "    if tree != None:\n",
    "      ans = ID3.evaluate(tree, dict(a=1, b=0))\n",
    "      if ans != 2:\n",
    "        print \"ID3 test 3-1 failed.\"\n",
    "      else:\n",
    "        print \"ID3 test 3-1 succeeded.\"\n",
    "      ans = ID3.evaluate(tree, dict(a=1, b=1))\n",
    "      if ans != 1:\n",
    "        print \"ID3 test 3-2 failed.\"\n",
    "      else:\n",
    "        print \"ID3 test 3-2 succeeded.\"\n",
    "    else:\n",
    "      print \"ID3 test 3 failed -- no tree returned\"\n",
    "  except Exception:\n",
    "    print 'ID3 test 3 failed runtime error'\n",
    "\n",
    "  data = [dict(a=1, b=0, c='?', Class=1), dict(a=1, b=3, c=2, Class=1),\n",
    "         dict(a=2, b='?', c=1, Class=2), dict(a=2, b=1, c=3, Class=2),\n",
    "         dict(a=3, b=0, c=1, Class=3), dict(a=3, b=2, c='?', Class=3)]\n",
    "\n",
    "  try:\n",
    "    tree = ID3.ID3(data, 0)\n",
    "    if tree != None:\n",
    "      ans = ID3.evaluate(tree, dict(a=1, b=1, c=1))\n",
    "      if ans != 1:\n",
    "        print \"ID3 test 4-1 failed.\"\n",
    "      else:\n",
    "        print \"ID3 test 4-1 succeeded.\"\n",
    "      ans = ID3.evaluate(tree, dict(a=2, b=0, c=0))\n",
    "      if ans != 2:\n",
    "        print \"ID3 test 4-2 failed.\"\n",
    "      else:\n",
    "        print \"ID3 test 4-2 succeeded.\"\n",
    "    else:\n",
    "      print \"ID3 test 4 failed -- no tree returned\"\n",
    "  except Exception:\n",
    "    print 'ID3 test 4 failed runtime error'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mini_grader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def testID3AndTest():\n",
    "  trainData = [dict(a=1, b=0, c=0, Class=1), dict(a=1, b=1, c=0, Class=1), \n",
    "  dict(a=0, b=0, c=0, Class=0), dict(a=0, b=1, c=0, Class=1)]\n",
    "  testData = [dict(a=1, b=0, c=1, Class=1), dict(a=1, b=1, c=1, Class=1), \n",
    "  dict(a=0, b=0, c=1, Class=0), dict(a=0, b=1, c=1, Class=0)]\n",
    "  tree = ID3.ID3(trainData, 0)\n",
    "  fails = 0\n",
    "  if tree != None:\n",
    "    acc = ID3.test(tree, trainData)\n",
    "    print acc\n",
    "    if acc == 1.0:\n",
    "      print \"testing on train data succeeded.\"\n",
    "    else:\n",
    "      print \"testing on train data failed.\"\n",
    "      fails = fails + 1\n",
    "    acc = ID3.test(tree, testData)\n",
    "    if acc == 0.75:\n",
    "      print \"testing on test data succeeded.\"\n",
    "    else:\n",
    "      print \"testing on test data failed.\"\n",
    "      fails = fails + 1\n",
    "    if fails > 0:\n",
    "      print \"Failures: \", fails\n",
    "    else:\n",
    "      print \"testID3AndTest succeeded.\"\n",
    "  else:\n",
    "    print \"testID3andTest failed -- no tree returned.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = [dict(a=1, b=0, c=0, Class=1), dict(a=1, b=1, c=0, Class=1), \n",
    "  dict(a=0, b=0, c=0, Class=0), dict(a=0, b=1, c=0, Class=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ID3.ID3(trainData, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(tree,dict(a=0,b=1,c=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'c': 0, 'b': 0, 'Class': 1}\n",
      "{'a': 1, 'c': 0, 'b': 0, 'Class': 1}\n",
      "Correct\n",
      "{'a': 1, 'c': 0, 'b': 1, 'Class': 1}\n",
      "{'a': 1, 'c': 0, 'b': 1, 'Class': 1}\n",
      "Correct\n",
      "{'a': 0, 'c': 0, 'b': 0, 'Class': 0}\n",
      "{'a': 0, 'c': 0, 'b': 0, 'Class': 0}\n",
      "Correct\n",
      "{'a': 0, 'c': 0, 'b': 1, 'Class': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(tree, trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(node, examples):\n",
    "  ''' \n",
    "  Takes in a trained tree and a test set of examples.  Returns the accuracy (fraction\n",
    "  of examples the tree classifies correctly).\n",
    "  '''\n",
    "\n",
    "  count = 0.0\n",
    "  for example in examples:\n",
    "      print example \n",
    "      exclass = evaluate(node, example)\n",
    "      if exclass == example['Class']:\n",
    "          print example\n",
    "          print 'Correct'\n",
    "          count += 1\n",
    "  acc = count / len(examples)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chooseBestAttribute(examples):\n",
    "  countDict = getCountDict(examples,'Class') \n",
    "  print countDict \n",
    "  entropy = 0.0\n",
    "  gain = 0.0\n",
    "  best=''\n",
    "  for (attribute, value) in countDict.iteritems():\n",
    "    valueResults = []\n",
    "    valueTotals = []\n",
    "    itemCounts = []\n",
    "    valTotal = 0.0\n",
    "    \n",
    " \n",
    "    for (val, targetAtts) in value.iteritems():\n",
    "        for key,count in targetAtts.iteritems():\n",
    "            \n",
    "            itemCounts.append(count)\n",
    "            valTotal+=count\n",
    "    \n",
    "    \n",
    "    for count in itemCounts:\n",
    "        probability = count/valTotal\n",
    "        entropy -= probability * math.log(probability,2)\n",
    "    \n",
    "    print itemCounts\n",
    "    for example in  :\n",
    "        gain += probability *entropy \n",
    "    ##times it by the probability in order to choose\n",
    "    if entropy>= gain:\n",
    "        gain = entropy \n",
    "        best = attribute\n",
    "    \n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    " data = [dict(a=1, b=0, c='?', Class=1), dict(a=1, b=3, c=2, Class=1),\n",
    "         dict(a=2, b='?', c=1, Class=2), dict(a=2, b=1, c=3, Class=2),\n",
    "         dict(a=3, b=0, c=1, Class=3), dict(a=3, b=2, c='?', Class=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-9ebaa9360811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchooseBestAttribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-6141c0fe53be>\u001b[0m in \u001b[0;36mchooseBestAttribute\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnewgain\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minfohelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mperson\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mnewgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-6141c0fe53be>\u001b[0m in \u001b[0;36minfohelper\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minfohelper\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mcountDict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgetCountDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-4bb27195cfc6>\u001b[0m in \u001b[0;36mgetCountDict\u001b[0;34m(examples, targetAtt)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# Going through each example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Getting all the attributes from that example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-6141c0fe53be>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((person,))\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnewgain\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minfohelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mperson\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mnewgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "chooseBestAttribute(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Class': {1: {1: 2}, 2: {2: 2}, 3: {3: 2}},\n",
       " 'a': {1: {1: 2}, 2: {2: 2}, 3: {3: 2}},\n",
       " 'b': {0: {1: 1, 3: 1}, 1: {2: 1}, 2: {3: 1}, 3: {1: 1}, '?': {2: 1}},\n",
       " 'c': {1: {2: 1, 3: 1}, 2: {1: 1}, 3: {2: 1}, '?': {1: 1, 3: 1}}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = getCountDict(data,'Class')\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestAttribute(examples):\n",
    "\n",
    "    countDict = getCountDict(examples,'Class')\n",
    "\n",
    "    gain = 0.0\n",
    "    best = ''\n",
    "    newgain = 0.0\n",
    "    for (attribute, dic) in countDict['Class'].iteritems():\n",
    "      for value, counter in dic.iteritems():\n",
    "        p = counter/len(examples)\n",
    "        newgain += p * infohelper(person for person in examples if person[attribute]==value)\n",
    "      newgain = abs(summation)\n",
    "    \n",
    "      if newgain>=gain: \n",
    "        gain = newgain \n",
    "        best = attribute \n",
    "    return best \n",
    "\n",
    "def infohelper (examples):\n",
    "  entropy = 0.0 \n",
    "  countDict= getCountDict(examples,'Class')\n",
    "  for key, counter in countDict['Class'].iteritems(): \n",
    "    counts= []\n",
    "    for val in counter: \n",
    "        counts.append(val)\n",
    "    for val in counts: \n",
    "        e -= (val/len(examples))*math.log((val/len(examples)),2)\n",
    "  return e \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getCountDict(examples, targetAtt):\n",
    "  '''\n",
    "\n",
    "  KEEP COUNT OF :\n",
    "  total amount of each attribute - eg: handicapped - # of yes, # of no, # of q...\n",
    "  within the particular value of an attribute - #democrat, # republican\n",
    "  '''\n",
    "\n",
    "  countDict = {}\n",
    "\n",
    "\n",
    "  # TODO: TAKE OUT CLASS FROM ATTRIBUTES\n",
    "\n",
    "  # Going through each example\n",
    "\n",
    "  for example in examples:\n",
    "\n",
    "    # Getting all the attributes from that example\n",
    "\n",
    "    for (attribute, value) in example.iteritems():\n",
    "\n",
    "      # Checking if that one attribute has already been looked at for other examples\n",
    "        \n",
    "\n",
    "        if attribute in countDict.keys():\n",
    "\n",
    "          # if it has that attribute, check to see if that value has already been looked at for that attribute for other examples\n",
    "\n",
    "            if value in countDict[attribute].keys():\n",
    "\n",
    "              # If it has that value, check to see if that value of the targetAtt has been looked at for that value of that attribute for other examples\n",
    "\n",
    "                if example[targetAtt] \\\n",
    "                    in countDict[attribute][value].keys():\n",
    "\n",
    "                  # If that value of that target attribute has already been looked at for this value of this attribute of this example, just incrememt it\n",
    "\n",
    "                    countDict[attribute][value][example[targetAtt]] += \\\n",
    "                        1\n",
    "                else:\n",
    "\n",
    "                  # Otherwise add that value of that target attribute to the dictionary\n",
    "\n",
    "                    countDict[attribute][value][example[targetAtt]] = \\\n",
    "                        1\n",
    "            else:\n",
    "\n",
    "              # Does not have the value, add that value and value of the TargetAtt to the dictionary\n",
    "\n",
    "                countDict[attribute][value] = {}\n",
    "                countDict[attribute][value][example[targetAtt]] = 1\n",
    "        else:\n",
    "            countDict[attribute] = {}\n",
    "            countDict[attribute][value] = {}\n",
    "            countDict[attribute][value][example[targetAtt]] = 1\n",
    "\n",
    "  return countDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    " data = [dict(a=1, b=0, c='?', Class=1), dict(a=1, b=3, c=2, Class=1),\n",
    "         dict(a=2, b='?', c=1, Class=2), dict(a=2, b=1, c=3, Class=2),\n",
    "         dict(a=3, b=0, c=1, Class=3), dict(a=3, b=2, c='?', Class=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-bcf34742d7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mentropy\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "import math\n",
    "entropy = 0.0 \n",
    "countDict = getCountDict(data,'Class')\n",
    "for (attribute, dic) in countDict['Class'].iteritems():\n",
    "    counters =[] \n",
    "    for val,freq in dic.iteritems(): \n",
    "        counters.append(freq) \n",
    "    for val in counters:\n",
    "        print attribute, val\n",
    "        print len(data)\n",
    "        p = val/len(data)\n",
    "        print P\n",
    "        entropy -= p * math.log(p,2)\n",
    "return entropy \n",
    "\n",
    "def infohelper (examples):\n",
    "  entropy = 0.0 \n",
    "  countDict= getCountDict(examples,'Class')\n",
    "  for key, counter in countDict['Class'].iteritems(): \n",
    "    counts= []\n",
    "    for val in counter: \n",
    "        counts.append(val)\n",
    "    for val in counts: \n",
    "        entropy -= (val/len(examples))*math.log((val/len(examples)),2)\n",
    "  return entropy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
